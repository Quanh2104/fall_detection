{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19BvAv8OHTH_RGA83Lw43NCV_esYXzEh9",
      "authorship_tag": "ABX9TyPsDqHOdECxbVW/aIuE25XZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quanh2104/fall_detection/blob/main/resnet50ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMvvws-NxJ7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1JJ9c5k0rJQo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj8ruX-5rNhX",
        "outputId": "b2a3e976-8e25-4b03-c901-d9f6845c06dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CÀI ĐẶT CÁC THAM SỐ ---\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS = 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_INITIAL = 20\n",
        "EPOCHS_FINE_TUNE = 30\n",
        "LEARNING_RATE_INITIAL = 1e-3\n",
        "LEARNING_RATE_FINE_TUNE = 1e-5"
      ],
      "metadata": {
        "id": "QdbBbFMSrZJ7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Đường dẫn\n",
        "DRIVE_PATH = '/content/drive/MyDrive/'\n",
        "CSV_FILE_PATH = os.path.join('/content/drive/MyDrive/Dataset_Gender_Age/thuy2.csv')\n",
        "IMAGE_DATA_DIR = os.path.join('/content/drive/MyDrive/Dataset_Gender_Age')\n"
      ],
      "metadata": {
        "id": "dLurW6ZVrmOr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AGE_CLASSES = ['Child', 'Teen', 'Adult', 'Elderly']\n",
        "GENDER_CLASSES = ['Male', 'Female']"
      ],
      "metadata": {
        "id": "wjCF71drr7Jz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tải và tiền xử lý data**\n"
      ],
      "metadata": {
        "id": "CNEA2VJlsJ1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc file CSV\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE_PATH)\n",
        "    print(f\"Tải thành công file CSV. Số lượng mẫu: {len(df)}\")\n",
        "    print(df.head(20))\n",
        "except FileNotFoundError:\n",
        "    print(f\"LỖI: Không tìm thấy file CSV tại: {CSV_FILE_PATH}\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDAw_R2hsHdv",
        "outputId": "b6ff39cd-1f46-4a86-81cf-b6754dc31582"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tải thành công file CSV. Số lượng mẫu: 3505\n",
            "                                                image  gender age group\n",
            "0   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "1   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "2   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "3   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "4   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "5   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "6   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "7   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "8   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "9   /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "10  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "11  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "12  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "13  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "14  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "15  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "16  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "17  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "18  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n",
            "19  /content/drive/MyDrive/Dataset_Gender_Age/Chil...  Female     Child\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['image_path'] = df['image']"
      ],
      "metadata": {
        "id": "OZAtfTaBkgVt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['image_path']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "zq-5h830k2B_",
        "outputId": "713eba7a-1d50-474a-821f-8c015fa6feca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       /content/drive/MyDrive/Dataset_Gender_Age/Chil...\n",
              "1       /content/drive/MyDrive/Dataset_Gender_Age/Chil...\n",
              "2       /content/drive/MyDrive/Dataset_Gender_Age/Chil...\n",
              "3       /content/drive/MyDrive/Dataset_Gender_Age/Chil...\n",
              "4       /content/drive/MyDrive/Dataset_Gender_Age/Chil...\n",
              "                              ...                        \n",
              "3500    /content/drive/MyDrive/Dataset_Gender_Age/Elde...\n",
              "3501    /content/drive/MyDrive/Dataset_Gender_Age/Elde...\n",
              "3502    /content/drive/MyDrive/Dataset_Gender_Age/Elde...\n",
              "3503    /content/drive/MyDrive/Dataset_Gender_Age/Elde...\n",
              "3504    /content/drive/MyDrive/Dataset_Gender_Age/Elde...\n",
              "Name: image_path, Length: 3505, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Chil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3500</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Elde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3501</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Elde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3502</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Elde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3503</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Elde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3504</th>\n",
              "      <td>/content/drive/MyDrive/Dataset_Gender_Age/Elde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3505 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Định nghĩa hàm load_and_preprocess_image ĐÚNG\n",
        "def load_and_preprocess_image(image_path, target_size=IMAGE_SIZE):\n",
        "    image_path_str = '' # Khởi tạo biến trước khối try\n",
        "    try:\n",
        "        image_path_str = image_path.numpy().decode('utf-8') # Gán giá trị cho biến bên trong try\n",
        "        image = tf.io.read_file(image_path)\n",
        "        image = tf.image.decode_image(image, channels=IMAGE_CHANNELS) # <-- Dùng tf.image.decode_image\n",
        "        print(f\"Đã giải mã ảnh: {image_path_str}\") # <-- Giữ lại dòng này để debug\n",
        "        image = tf.image.resize(image, target_size)\n",
        "        image = image / 255.0  # Chuẩn hóa về [0, 1]\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tải hoặc xử lý ảnh '{image_path_str}': {e}\") # <-- Giữ lại dòng này để báo lỗi ảnh\n",
        "        return None"
      ],
      "metadata": {
        "id": "2Dls5RErC8hT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mã hóa nhãn\n",
        "# Giới tính:\n",
        "gender_encoder = LabelEncoder()\n",
        "df['gender_encoded'] = gender_encoder.fit_transform(df['gender'])\n",
        "print(\"\\nCác lớp giới tính sau mã hóa:\", gender_encoder.classes_) # Sẽ là [0, 1] hoặc ['Female', 'Male'] tùy theo dữ liệu\n",
        "\n",
        "gender_one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "gender_labels_one_hot = gender_one_hot_encoder.fit_transform(df['gender_encoded'].values.reshape(-1, 1))\n",
        "print(\"Ví dụ nhãn giới tính one-hot:\", gender_labels_one_hot[:5])\n",
        "\n",
        "# Nhóm tuổi\n",
        "age_encoder = LabelEncoder()\n",
        "df['age_group_encoded'] = age_encoder.fit_transform(df['age group'])\n",
        "print(\"\\nCác lớp nhóm tuổi sau mã hóa:\", age_encoder.classes_) # ['Adult', 'Child', 'Elderly', 'Teenager'] (thứ tự tùy thuộc vào dữ liệu)\n",
        "\n",
        "age_one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "age_labels_one_hot = age_one_hot_encoder.fit_transform(df['age_group_encoded'].values.reshape(-1, 1))\n",
        "print(\"Ví dụ nhãn nhóm tuổi one-hot:\", age_labels_one_hot[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XPBKMa5oexB",
        "outputId": "441d0645-6a45-4999-becc-b2912ab59092"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Các lớp giới tính sau mã hóa: ['Female' 'Male']\n",
            "Ví dụ nhãn giới tính one-hot: [[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "\n",
            "Các lớp nhóm tuổi sau mã hóa: ['Adult' 'Child' 'Elderly' 'Teen']\n",
            "Ví dụ nhãn nhóm tuổi one-hot: [[0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn bị danh sách đường dẫn ảnh và nhãn\n",
        "image_paths = df['image_path'].tolist()\n",
        "\n",
        "gender_labels_binary = df['gender_encoded'].values # Sử dụng trực tiếp 0 hoặc 1\n",
        "labels_gender = gender_labels_binary\n",
        "labels_age = age_labels_one_hot\n"
      ],
      "metadata": {
        "id": "pcQvm5FLta3t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tỉ lệ: 70% train, 15% validation, 15% test\n",
        "X_train_paths, X_temp_paths, y_train_gender, y_temp_gender, y_train_age, y_temp_age = train_test_split(\n",
        "    image_paths, labels_gender, labels_age, test_size=0.3, random_state=42, stratify=df['age_group_encoded'] # Stratify theo tuổi để đảm bảo phân bố\n",
        ")\n",
        "X_val_paths, X_test_paths, y_val_gender, y_test_gender, y_val_age, y_test_age = train_test_split(\n",
        "    X_temp_paths, y_temp_gender, y_temp_age, test_size=0.5, random_state=42, stratify=y_temp_age.argmax(axis=1) if y_temp_age.ndim > 1 else y_temp_age\n",
        ")\n",
        "\n",
        "print(f\"\\nKích thước tập huấn luyện: {len(X_train_paths)}\")\n",
        "print(f\"Kích thước tập kiểm định: {len(X_val_paths)}\")\n",
        "print(f\"Kích thước tập kiểm thử: {len(X_test_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPRPdbFRoscx",
        "outputId": "7b7d5f01-d781-45e0-9eba-ea8637e2c4ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kích thước tập huấn luyện: 2453\n",
            "Kích thước tập kiểm định: 526\n",
            "Kích thước tập kiểm thử: 526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hàm tạo dataset từ đường dẫn và nhãn\n",
        "# def create_dataset(image_paths, gender_labels, age_labels, batch_size):\n",
        "\n",
        "#     path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "\n",
        "#     image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "#     label_ds_gender = tf.data.Dataset.from_tensor_slices(tf.cast(gender_labels, tf.float32)) # Gender: 0 hoặc 1\n",
        "#     label_ds_age = tf.data.Dataset.from_tensor_slices(tf.cast(age_labels, tf.float32)) # Age: one-hot\n",
        "#     image_label_ds = tf.data.Dataset.zip((image_ds, {\"gender_output\": label_ds_gender, \"age_output\": label_ds_age}))\n",
        "#     dataset = image_label_ds.shuffle(buffer_size=len(image_paths))\n",
        "#     dataset = dataset.batch(batch_size)\n",
        "#     dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE) # Tối ưu hóa hiệu suất\n",
        "#     return dataset\n"
      ],
      "metadata": {
        "id": "-jhlUFxro1n_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(image_paths, gender_labels, age_labels, batch_size):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "\n",
        "    # Sử dụng hàm map tùy chỉnh trả về ảnh và nhãn, và lọc bỏ ảnh None\n",
        "    def load_and_filter(image_path, gender_label, age_label):\n",
        "        image = load_and_preprocess_image(image_path)\n",
        "        # Trả về cấu trúc có thể lọc, bao gồm cả nhãn\n",
        "        return image, gender_label, age_label\n",
        "\n",
        "    image_label_ds = tf.data.Dataset.from_tensor_slices((image_paths, gender_labels, age_labels))\n",
        "    image_label_ds = image_label_ds.map(\n",
        "        load_and_filter,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    # Lọc bỏ các mục mà ảnh là None\n",
        "    image_label_ds = image_label_ds.filter(lambda image, gender_label, age_label: image is not None)\n",
        "\n",
        "    # Tách dataset đã lọc trở lại cấu trúc mong muốn, đặt tên cho output\n",
        "    # This defines the output shapes explicitly\n",
        "    image_label_ds = image_label_ds.map(lambda image, gender_label, age_label: (image, {\"gender_output\": tf.cast(gender_label, tf.float32), \"age_output\": tf.cast(age_label, tf.float32)}),\n",
        "                                        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "                                        deterministic=False)\n",
        "\n",
        "    dataset = image_label_ds.shuffle(buffer_size=len(image_paths)) # Kích thước buffer có thể cần điều chỉnh sau khi lọc\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE) # Tối ưu hóa hiệu suất\n",
        "    return dataset\n",
        "    def is_valid_path(image_path, gender_label, age_label):\n",
        "        image = load_and_preprocess_image(image_path)\n",
        "        return image is not None  # True if valid, False if not\n",
        "\n",
        "    image_label_ds = image_label_ds.filter(is_valid_path)"
      ],
      "metadata": {
        "id": "MHAo87xTID9I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_preprocess_image(image_path, target_size=IMAGE_SIZE):\n",
        "#     # Use tf.py_function to wrap the eager execution part\n",
        "#     def _load_and_preprocess_image_eager(image_path):\n",
        "#         image_path_str = image_path.numpy().decode('utf-8')  # Now safe to use .numpy()\n",
        "#         image = tf.io.read_file(image_path_str)\n",
        "#         image = tf.image.decode_image(image, channels=IMAGE_CHANNELS)\n",
        "#         print(f\"Đã giải mã ảnh: {image_path_str}\")\n",
        "#         image = tf.image.resize(image, target_size)\n",
        "#         image = image / 255.0  # Chuẩn hóa về [0, 1]\n",
        "#         return image\n",
        "\n",
        "#     # Apply tf.py_function\n",
        "#     return tf.py_function(\n",
        "#         _load_and_preprocess_image_eager,\n",
        "#         [image_path],\n",
        "#         tf.float32\n",
        "#     )"
      ],
      "metadata": {
        "id": "TG98at16MEEu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_dataset(X_train_paths, y_train_gender, y_train_age, BATCH_SIZE)\n",
        "val_dataset = create_dataset(X_val_paths, y_val_gender, y_val_age, BATCH_SIZE)\n",
        "test_dataset = create_dataset(X_test_paths, y_test_gender, y_test_age, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "_HQuajAVuiY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05503d5b-c7ba-4f66-c23f-33582f4b8335"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lỗi khi tải hoặc xử lý ảnh '': 'SymbolicTensor' object has no attribute 'numpy'\n",
            "Lỗi khi tải hoặc xử lý ảnh '': 'SymbolicTensor' object has no attribute 'numpy'\n",
            "Lỗi khi tải hoặc xử lý ảnh '': 'SymbolicTensor' object has no attribute 'numpy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\\nKiểm tra shape của một batch dữ liệu:\")\n",
        "# try:\n",
        "#     for images, labels in train_dataset.take(1):\n",
        "#         print(\"Train batch images shape:\", images.shape)\n",
        "#         print(\"Train batch gender labels shape:\", labels['gender_output'].shape)\n",
        "#         print(\"Train batch age labels shape:\", labels['age_output'].shape)\n",
        "# except Exception as e:\n",
        "#     print(f\"Lỗi khi lấy một batch từ train_dataset: {e}\")\n",
        "\n",
        "# try:\n",
        "#     for images, labels in val_dataset.take(1):\n",
        "#         print(\"Validation batch images shape:\", images.shape)\n",
        "#         # print(\"Validation batch gender labels shape:\", labels['gender_output'].shape)\n",
        "#         print(\"Validation batch age labels shape:\", labels['age_output'].shape)\n",
        "# except Exception as e:\n",
        "#     print(f\"Lỗi khi lấy một batch từ val_dataset: {e}\")\n",
        "\n",
        "# try:\n",
        "#     for images, labels in test_dataset.take(1):\n",
        "#         print(\"Test batch images shape:\", images.shape)\n",
        "#         print(\"Test batch gender labels shape:\", labels['gender_output'].shape)\n",
        "#         print(\"Test batch age labels shape:\", labels['age_output'].shape)\n",
        "# except Exception as e:\n",
        "#     print(f\"Lỗi khi lấy một batch từ test_dataset: {e}\")"
      ],
      "metadata": {
        "id": "8OTuMLpUFEti"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ... (previous code)\n",
        "\n",
        "# # Xóa các hàng có đường dẫn không hợp lệ khỏi DataFrame\n",
        "# invalid_paths = []\n",
        "# for i in range(len(df)):\n",
        "#     path_to_check = df['image_path'].iloc[i]\n",
        "#     if not os.path.exists(path_to_check):\n",
        "#         invalid_paths.append(i)\n",
        "\n",
        "# # Check if all paths are invalid before dropping\n",
        "# if len(invalid_paths) == len(df):\n",
        "#     print(\"ERROR: All image paths are invalid. Please check your dataset.\")\n",
        "#     # Handle the case where all paths are invalid, e.g., exit the script\n",
        "#     # or provide an option to the user to fix the paths.\n",
        "#     exit()\n",
        "# else:\n",
        "#     df = df.drop(invalid_paths).reset_index(drop=True) # Reset index after dropping invalid paths\n",
        "#     print(f\"Đã xóa {len(invalid_paths)} hàng có đường dẫn không hợp lệ.\")\n",
        "\n",
        "# # Recreate X_train_paths, y_train_gender, etc. after removing invalid paths\n",
        "# image_paths = df['image_path'].tolist()\n",
        "# gender_labels_binary = df['gender_encoded'].values\n",
        "# labels_gender = gender_labels_binary\n",
        "# labels_age = age_one_hot_encoder.transform(df['age_group_encoded'].values.reshape(-1, 1)) # Re-encode age\n",
        "\n",
        "# # Redo the train-test split with the updated data\n",
        "# X_train_paths, X_temp_paths, y_train_gender, y_temp_gender, y_train_age, y_temp_age = train_test_split(\n",
        "#     image_paths, labels_gender, labels_age, test_size=0.3, random_state=42, stratify=df['age_group_encoded']\n",
        "# )\n",
        "# X_val_paths, X_test_paths, y_val_gender, y_test_gender, y_val_age, y_test_age = train_test_split(\n",
        "#     X_temp_paths, y_temp_gender, y_temp_age, test_size=0.5, random_state=42, stratify=y_temp_age.argmax(axis=1) if y_temp_age.ndim > 1 else y_temp_age\n",
        "# )\n",
        "\n",
        "# # Recreate datasets with the updated paths and labels\n",
        "# train_dataset = create_dataset(X_train_paths, y_train_gender, y_train_age, BATCH_SIZE)\n",
        "# val_dataset = create_dataset(X_val_paths, y_val_gender, y_val_age, BATCH_SIZE)\n",
        "# test_dataset = create_dataset(X_test_paths, y_test_gender, y_test_age, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "TvOIevI-mCnB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra một batch dữ liệu\n",
        "for images, labels in train_dataset.take(1):\n",
        "    print(\"\\nShapes của một batch dữ liệu huấn luyện:\")\n",
        "    print(\"Images shape:\", images.shape)\n",
        "    print(\"Gender labels shape:\", labels['gender_output'].shape)\n",
        "    print(\"Age labels shape:\", labels['age_output'].shape)\n",
        "    # Hiển thị một vài ảnh ví dụ\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(min(9, images.shape[0])): # Hiển thị tối đa 9 ảnh\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy()) # .numpy() để chuyển tensor sang numpy array\n",
        "        gender_pred_idx = int(round(labels['gender_output'][i].numpy())) # Nếu là sigmoid output\n",
        "        age_pred_idx = np.argmax(labels['age_output'][i].numpy())\n",
        "        plt.title(f\"G: {GENDER_CLASSES[gender_pred_idx]}\\nA: {AGE_CLASSES[age_pred_idx]}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "xxyNknKuuunZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(image_paths, gender_labels, age_labels, batch_size):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "\n",
        "    # Sử dụng hàm map tùy chỉnh trả về ảnh và nhãn, và lọc bỏ ảnh None\n",
        "    def load_and_filter(image_path, gender_label, age_label):\n",
        "        image = load_and_preprocess_image(image_path)\n",
        "        # Trả về cấu trúc có thể lọc\n",
        "        return image, gender_label, age_label\n",
        "\n",
        "    image_label_ds = tf.data.Dataset.from_tensor_slices((image_paths, gender_labels, age_labels))\n",
        "    image_label_ds = image_label_ds.map(\n",
        "        load_and_filter,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    # Lọc bỏ các mục mà ảnh là None\n",
        "    image_label_ds = image_label_ds.filter(lambda image, gender_label, age_label: image is not None)\n",
        "\n",
        "    # Tách dataset đã lọc trở lại cấu trúc mong muốn\n",
        "    image_ds = image_label_ds.map(lambda image, gender_label, age_label: image)\n",
        "    label_ds_gender = image_label_ds.map(lambda image, gender_label, age_label: tf.cast(gender_label, tf.float32))\n",
        "    label_ds_age = image_label_ds.map(lambda image, gender_label, age_label: tf.cast(age_label, tf.float32))\n",
        "\n",
        "    # Ghép lại dataset\n",
        "    image_label_ds = tf.data.Dataset.zip((image_ds, {\"gender_output\": label_ds_gender, \"age_output\": label_ds_age}))\n",
        "\n",
        "    dataset = image_label_ds.shuffle(buffer_size=len(image_paths)) # Kích thước buffer có thể cần điều chỉnh sau khi lọc\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE) # Tối ưu hóa hiệu suất\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "evyeaROTDvNI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. XÂY DỰNG MÔ HÌNH ResNet50 ---\n",
        "def build_resnet50_model(image_size=IMAGE_SIZE, num_age_classes=len(AGE_CLASSES)):\n",
        "    # Tải ResNet50 pre-trained trên ImageNet, không bao gồm lớp fully connected ở trên cùng\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False,\n",
        "                          input_shape=(image_size[0], image_size[1], IMAGE_CHANNELS))\n",
        "\n",
        "    # Đóng băng các lớp của base_model để không huấn luyện lại trong giai đoạn đầu\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Xây dựng phần đầu của mô hình (custom head)\n",
        "    inputs = Input(shape=(image_size[0], image_size[1], IMAGE_CHANNELS))\n",
        "    x = base_model(inputs, training=False) # Quan trọng: training=False khi base_model bị đóng băng\n",
        "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "\n",
        "    # Nhánh cho Nhóm tuổi (Age)\n",
        "    age_branch = Dense(256, activation='relu', name='age_dense_1')(x)\n",
        "    age_branch = BatchNormalization(name='age_bn_1')(age_branch)\n",
        "    age_branch = Dropout(0.5, name='age_dropout_1')(age_branch) # Dropout để chống overfitting\n",
        "    age_branch = Dense(128, activation='relu', name='age_dense_2')(age_branch)\n",
        "    age_branch = BatchNormalization(name='age_bn_2')(age_branch)\n",
        "    age_branch = Dropout(0.3, name='age_dropout_2')(age_branch)\n",
        "    age_output = Dense(num_age_classes, activation='softmax', name='age_output')(age_branch)\n",
        "\n",
        "    # Nhánh cho Giới tính (Gender)\n",
        "    gender_branch = Dense(128, activation='relu', name='gender_dense_1')(x) # Có thể dùng ít lớp hơn cho gender\n",
        "    gender_branch = BatchNormalization(name='gender_bn_1')(gender_branch)\n",
        "    gender_branch = Dropout(0.5, name='gender_dropout_1')(gender_branch)\n",
        "    # Sử dụng 1 unit với sigmoid cho binary classification (Male/Female)\n",
        "    gender_output = Dense(1, activation='sigmoid', name='gender_output')(gender_branch)\n",
        "    # Hoặc 2 units với softmax nếu bạn mã hóa one-hot cho gender\n",
        "    # gender_output = Dense(2, activation='softmax', name='gender_output')(gender_branch)\n",
        "\n",
        "\n",
        "    # Tạo mô hình với 1 đầu vào và 2 đầu ra\n",
        "    model = Model(inputs=inputs, outputs=[gender_output, age_output], name=\"ResNet50_Gender_Age\")\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_resnet50_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "v6P_aO9o1zFx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "outputId": "3ae9763f-7ef9-4e3b-ae0f-91a25d258a1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ResNet50_Gender_Age\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50_Gender_Age\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ resnet50            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │ \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ avg_pool            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dense_1 (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m524,544\u001b[0m │ avg_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_bn_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ age_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ age_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_dense_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m262,272\u001b[0m │ avg_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dense_2 (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ age_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_bn_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ gender_dense_1[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_bn_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ age_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_dropout_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ gender_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ age_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ gender_dropout_1… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ age_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ resnet50            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ avg_pool            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_bn_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ age_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ age_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_dense_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │ avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ age_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_bn_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ gender_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_bn_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ age_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_dropout_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gender_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ age_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gender_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ gender_dropout_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ age_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ age_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,410,117\u001b[0m (93.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,410,117</span> (93.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m821,381\u001b[0m (3.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">821,381</span> (3.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,588,736\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,588,736</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile mô hình\n",
        "# Định nghĩa losses và loss_weights\n",
        "losses = {\n",
        "    \"gender_output\": \"binary_crossentropy\", # Vì gender_output dùng sigmoid (1 unit)\n",
        "    # \"gender_output\": \"categorical_crossentropy\", # Nếu gender_output dùng softmax (2 units)\n",
        "    \"age_output\": \"categorical_crossentropy\"  # Vì age_output dùng softmax (4 units)\n",
        "}\n",
        "loss_weights = {\"gender_output\": 0.5, \"age_output\": 0.5} # Có thể điều chỉnh trọng số\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE_INITIAL),\n",
        "              loss=losses,\n",
        "              loss_weights=loss_weights,\n",
        "              metrics={\n",
        "                  \"gender_output\": \"accuracy\", # Hoặc tf.keras.metrics.BinaryAccuracy()\n",
        "                  \"age_output\": \"accuracy\"   # Hoặc tf.keras.metrics.CategoricalAccuracy()\n",
        "              })\n"
      ],
      "metadata": {
        "id": "Fya_Rgj33G7G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "er-aEdbpnpwf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. HUẤN LUYỆN GIAI ĐOẠN 1 (CHỈ HUẤN LUYỆN CÁC LỚP MỚI) ---\n",
        "print(\"\\n--- BẮT ĐẦU HUẤN LUYỆN GIAI ĐOẠN 1 (TRANSFER LEARNING) ---\")\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_path_initial = os.path.join(DRIVE_PATH, \"resnet50_gender_age_initial_best.keras\") #Lưu dưới dạng .keras\n",
        "model_checkpoint_initial = ModelCheckpoint(filepath=checkpoint_path_initial,\n",
        "                                           save_best_only=True,\n",
        "                                           monitor='val_age_output_accuracy', # Theo dõi accuracy của nhánh tuổi trên tập val\n",
        "                                           mode='max',\n",
        "                                           verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', # Theo dõi tổng loss trên tập val\n",
        "                               patience=10, # Dừng nếu không cải thiện sau 10 epochs\n",
        "                               verbose=1,\n",
        "                               mode='min',\n",
        "                               restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2, # Giảm LR đi 5 lần\n",
        "                              patience=5,\n",
        "                              verbose=1,\n",
        "                              mode='min',\n",
        "                              min_lr=1e-7)\n",
        "\n",
        "history_initial = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS_INITIAL,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[model_checkpoint_initial, early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Tải lại trọng số tốt nhất từ giai đoạn 1\n",
        "# model.load_weights(checkpoint_path_initial) # Đã có restore_best_weights=True trong EarlyStopping\n"
      ],
      "metadata": {
        "id": "s9kyAuCC3NEB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a1641f1c-eb5b-4c7a-b95d-46b7d210c59e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BẮT ĐẦU HUẤN LUYỆN GIAI ĐOẠN 1 (TRANSFER LEARNING) ---\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Inputs to a layer should be tensors. Got 'None' (of type <class 'NoneType'>) as input for layer 'ResNet50_Gender_Age'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-41f31d973708>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                               min_lr=1e-7)\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history_initial = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS_INITIAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# which does not have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0;34mf\"Inputs to a layer should be tensors. Got '{x}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;34mf\"(of type {type(x)}) as input for layer '{layer_name}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Inputs to a layer should be tensors. Got 'None' (of type <class 'NoneType'>) as input for layer 'ResNet50_Gender_Age'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. FINE-TUNING (MỞ BĂNG MỘT PHẦN HOẶC TOÀN BỘ ResNet50) ---\n",
        "print(\"\\n--- BẮT ĐẦU HUẤN LUYỆN GIAI ĐOẠN 2 (FINE-TUNING) ---\")\n",
        "\n",
        "base_model = model.get_layer('resnet50') # Lấy lại base_model từ mô hình đã xây dựng\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = False\n",
        "\n",
        "# Re-compile mô hình với learning rate nhỏ hơn nhiều cho fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE_FINE_TUNE), # LR rất nhỏ\n",
        "              loss=losses,\n",
        "              loss_weights=loss_weights,\n",
        "              metrics={\n",
        "                  \"gender_output\": \"accuracy\",\n",
        "                  \"age_output\": \"accuracy\"\n",
        "              })\n",
        "\n",
        "model.summary() # Xem lại các lớp trainable\n",
        "\n",
        "# Callbacks cho fine-tuning\n",
        "checkpoint_path_fine_tune = os.path.join(DRIVE_PATH, \"resnet50_gender_age_fine_tune_best.keras\")\n",
        "model_checkpoint_fine_tune = ModelCheckpoint(filepath=checkpoint_path_fine_tune,\n",
        "                                             save_best_only=True,\n",
        "                                             monitor='val_age_output_accuracy',\n",
        "                                             mode='max',\n",
        "                                             verbose=1)\n",
        "# Có thể dùng lại early_stopping và reduce_lr đã định nghĩa ở trên, hoặc tạo mới với patience khác\n",
        "early_stopping_ft = EarlyStopping(monitor='val_loss', patience=15, verbose=1, mode='min', restore_best_weights=True)\n",
        "reduce_lr_ft = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1, mode='min', min_lr=1e-8)\n",
        "\n",
        "\n",
        "history_fine_tune = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS_FINE_TUNE,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[model_checkpoint_fine_tune, early_stopping_ft, reduce_lr_ft],\n",
        "    initial_epoch=history_initial.epoch[-1] # Tiếp tục từ epoch cuối của giai đoạn 1 (nếu muốn)\n",
        ")\n",
        "\n",
        "# Tải lại trọng số tốt nhất từ giai đoạn fine-tuning\n",
        "model.load_weights(checkpoint_path_fine_tune)\n"
      ],
      "metadata": {
        "id": "Io26QV6qF8U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. ĐÁNH GIÁ MÔ HÌNH TRÊN TẬP TEST ---\n",
        "print(\"\\n--- ĐÁNH GIÁ MÔ HÌNH TRÊN TẬP KIỂM THỬ ---\")\n",
        "results = model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "print(\"\\nKết quả đánh giá trên tập Test:\")\n",
        "print(f\"Total Loss: {results[0]:.4f}\")\n",
        "print(f\"Gender Loss: {results[1]:.4f} - Gender Accuracy: {results[3]:.4f}\") # Index có thể thay đổi, kiểm tra model.metrics_names\n",
        "print(f\"Age Loss: {results[2]:.4f} - Age Accuracy: {results[4]:.4f}\")\n",
        "# In ra model.metrics_names để biết đúng index của từng metric\n",
        "print(\"Model metrics names:\", model.metrics_names)\n",
        "\n",
        "\n",
        "# Lấy dự đoán trên tập test để xem xét chi tiết hơn\n",
        "y_pred_test = model.predict(test_dataset)\n",
        "y_pred_gender_proba = y_pred_test[0] # Xác suất cho gender\n",
        "y_pred_age_proba = y_pred_test[1]    # Xác suất cho age\n",
        "\n",
        "# Chuyển đổi xác suất thành nhãn lớp\n",
        "y_pred_gender_classes = (y_pred_gender_proba > 0.5).astype(\"int32\").flatten() # Ngưỡng 0.5 cho sigmoid\n",
        "# y_pred_gender_classes = np.argmax(y_pred_gender_proba, axis=1) # Nếu gender dùng softmax\n",
        "y_pred_age_classes = np.argmax(y_pred_age_proba, axis=1)\n",
        "\n",
        "# Lấy nhãn thực tế từ test_dataset (cần phải lặp q///////ua dataset để lấy hết)\n",
        "y_true_gender = []\n",
        "y_true_age = []\n",
        "for _, labels_batch in test_dataset:\n",
        "    y_true_gender.extend(labels_batch['gender_output'].numpy().flatten().astype(int))\n",
        "    y_true_age.extend(np.argmax(labels_batch['age_output'].numpy(), axis=1))\n",
        "\n",
        "y_true_gender = np.array(y_true_gender)\n",
        "y_true_age = np.array(y_true_age)\n",
        "\n"
      ],
      "metadata": {
        "id": "7omlNmx7qinQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Báo cáo phân loại và Ma trận nhầm lẫn\n",
        "print(\"\\n--- BÁO CÁO PHÂN LOẠI CHO GIỚI TÍNH ---\")\n",
        "print(classification_report(y_true_gender, y_pred_gender_classes, target_names=GENDER_CLASSES))\n",
        "cm_gender = confusion_matrix(y_true_gender, y_pred_gender_classes)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_gender, annot=True, fmt='d', cmap='Blues', xticklabels=GENDER_CLASSES, yticklabels=GENDER_CLASSES)\n",
        "plt.title('Confusion Matrix - Gender')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- BÁO CÁO PHÂN LOẠI CHO NHÓM TUỔI ---\")\n",
        "# Đảm bảo target_names khớp với thứ tự của age_encoder.classes_\n",
        "print(classification_report(y_true_age, y_pred_age_classes, target_names=age_encoder.classes_))\n",
        "cm_age = confusion_matrix(y_true_age, y_pred_age_classes)\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm_age, annot=True, fmt='d', cmap='Blues', xticklabels=age_encoder.classes_, yticklabels=age_encoder.classes_)\n",
        "plt.title('Confusion Matrix - Age Group')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QaUAKLGjqnR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. VẼ BIỂU ĐỒ QUÁ TRÌNH HUẤN LUYỆN ---\n",
        "def plot_training_history(history1, history2=None, stage1_name=\"Initial Training\", stage2_name=\"Fine-tuning\"):\n",
        "    acc_gender_initial = history1.history['gender_output_accuracy']\n",
        "    val_acc_gender_initial = history1.history['val_gender_output_accuracy']\n",
        "    loss_gender_initial = history1.history['gender_output_loss'] # Hoặc 'loss' nếu chỉ có 1 loss\n",
        "    val_loss_gender_initial = history1.history['val_gender_output_loss'] # Hoặc 'val_loss'\n",
        "\n",
        "    acc_age_initial = history1.history['age_output_accuracy']\n",
        "    val_acc_age_initial = history1.history['val_age_output_accuracy']\n",
        "    loss_age_initial = history1.history['age_output_loss']\n",
        "    val_loss_age_initial = history1.history['val_age_output_loss']\n",
        "\n",
        "    epochs_range_initial = range(len(acc_gender_initial))\n",
        "\n",
        "    plt.figure(figsize=(20, 12))\n",
        "\n",
        "    # Gender Accuracy - Giai đoạn 1\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs_range_initial, acc_gender_initial, label=f'{stage1_name} Gender Training Acc')\n",
        "    plt.plot(epochs_range_initial, val_acc_gender_initial, label=f'{stage1_name} Gender Validation Acc')\n",
        "    if history2:\n",
        "        acc_gender_ft = history2.history['gender_output_accuracy']\n",
        "        val_acc_gender_ft = history2.history['val_gender_output_accuracy']\n",
        "        epochs_range_ft = range(len(acc_gender_initial), len(acc_gender_initial) + len(acc_gender_ft))\n",
        "        plt.plot(epochs_range_ft, acc_gender_ft, label=f'{stage2_name} Gender Training Acc')\n",
        "        plt.plot(epochs_range_ft, val_acc_gender_ft, label=f'{stage2_name} Gender Validation Acc')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Gender Training and Validation Accuracy')\n",
        "\n",
        "    # Gender Loss - Giai đoạn 1\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs_range_initial, loss_gender_initial, label=f'{stage1_name} Gender Training Loss')\n",
        "    plt.plot(epochs_range_initial, val_loss_gender_initial, label=f'{stage1_name} Gender Validation Loss')\n",
        "    if history2:\n",
        "        loss_gender_ft = history2.history['gender_output_loss']\n",
        "        val_loss_gender_ft = history2.history['val_gender_output_loss']\n",
        "        epochs_range_ft = range(len(loss_gender_initial), len(loss_gender_initial) + len(loss_gender_ft))\n",
        "        plt.plot(epochs_range_ft, loss_gender_ft, label=f'{stage2_name} Gender Training Loss')\n",
        "        plt.plot(epochs_range_ft, val_loss_gender_ft, label=f'{stage2_name} Gender Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Gender Training and Validation Loss')\n",
        "\n",
        "    # Age Accuracy - Giai đoạn 1\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs_range_initial, acc_age_initial, label=f'{stage1_name} Age Training Acc')\n",
        "    plt.plot(epochs_range_initial, val_acc_age_initial, label=f'{stage1_name} Age Validation Acc')\n",
        "    if history2:\n",
        "        acc_age_ft = history2.history['age_output_accuracy']\n",
        "        val_acc_age_ft = history2.history['val_age_output_accuracy']\n",
        "        epochs_range_ft = range(len(acc_age_initial), len(acc_age_initial) + len(acc_age_ft))\n",
        "        plt.plot(epochs_range_ft, acc_age_ft, label=f'{stage2_name} Age Training Acc')\n",
        "        plt.plot(epochs_range_ft, val_acc_age_ft, label=f'{stage2_name} Age Validation Acc')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Age Group Training and Validation Accuracy')\n",
        "\n",
        "    # Age Loss - Giai đoạn 1\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs_range_initial, loss_age_initial, label=f'{stage1_name} Age Training Loss')\n",
        "    plt.plot(epochs_range_initial, val_loss_age_initial, label=f'{stage1_name} Age Validation Loss')\n",
        "    if history2:\n",
        "        loss_age_ft = history2.history['age_output_loss']\n",
        "        val_loss_age_ft = history2.history['val_age_output_loss']\n",
        "        epochs_range_ft = range(len(loss_age_initial), len(loss_age_initial) + len(loss_age_ft))\n",
        "        plt.plot(epochs_range_ft, loss_age_ft, label=f'{stage2_name} Age Training Loss')\n",
        "        plt.plot(epochs_range_ft, val_loss_age_ft, label=f'{stage2_name} Age Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Age Group Training and Validation Loss')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history_initial, history_fine_tune)"
      ],
      "metadata": {
        "id": "9zw6RdtOqrHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. LƯU MÔ HÌNH CUỐI CÙNG ---\n",
        "final_model_path = os.path.join(DRIVE_PATH, \"resnet50_gender_age_final_model.keras\")\n",
        "model.save(final_model_path)\n",
        "print(f\"\\nMô hình cuối cùng đã được lưu tại: {final_model_path}\")\n"
      ],
      "metadata": {
        "id": "SCAHhAPjqu6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 9. (TÙY CHỌN) DỰ ĐOÁN TRÊN ẢNH MỚI ---\n",
        "def predict_single_image(image_path, model_loaded, age_encoder_classes, gender_classes_map):\n",
        "    img = load_and_preprocess_image(image_path)\n",
        "    if img is None:\n",
        "        return None, None\n",
        "    img_array = tf.expand_dims(img, 0) # Tạo batch dimension\n",
        "\n",
        "    predictions = model_loaded.predict(img_array)\n",
        "    gender_pred_proba = predictions[0][0][0] # Xác suất giới tính (sigmoid output)\n",
        "    age_pred_proba = predictions[1][0]       # Mảng xác suất các nhóm tuổi\n",
        "\n",
        "    gender_label = gender_classes_map[int(round(gender_pred_proba))]\n",
        "    age_label = age_encoder_classes[np.argmax(age_pred_proba)]\n",
        "\n",
        "    # Hiển thị ảnh và dự đoán\n",
        "    plt.imshow(img.numpy())\n",
        "    plt.title(f\"Predicted Gender: {gender_label} ({gender_pred_proba:.2f})\\nPredicted Age Group: {age_label} ({np.max(age_pred_proba):.2f})\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    return gender_label, age_label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NUikRQXmqxPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ví dụ sử dụng '\n",
        "test_image_path = os.path.join('/content/drive/MyDrive/Dataset_Gender_Age/Child/Female/viet_child_783.jpg')\n",
        "GENDER_MAP_FOR_PREDICTION = {0: 'Male', 1: 'Female'}\n",
        "loaded_model = tf.keras.models.load_model(final_model_path)\n",
        "predict_single_image(test_image_path, loaded_model, age_encoder.classes_, GENDER_MAP_FOR_PREDICTION)"
      ],
      "metadata": {
        "id": "hWZJgCmJq168"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}